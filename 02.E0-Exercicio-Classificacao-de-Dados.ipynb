{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sincendz/mineracao-de-dados/blob/main/02.E0-Exercicio-Classificacao-de-Dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd3xc9HB07qb"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/paulotguerra/QXD0178/blob/main/02.E0-Exercicio-Classificacao-de-dados.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD2tIhva07qk"
      },
      "source": [
        "## QXD0178 - Mineração de Dados\n",
        "# Classificação de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-nSN6Kw07ql"
      },
      "source": [
        "**Professor:** Paulo de Tarso Guerra Oliveira ([paulodetarso@ufc.br](mailto:paulodetarso@ufc.br))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcPco-ZP07qm"
      },
      "source": [
        "# Lista de Exercícios: Classificação de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w44dxv907qn"
      },
      "source": [
        "Nesta lista de exercícios, você explorará a aplicação de métodos de aprendizado de máquina para realizar tarefas de classificação de dados. Você usará a base de dados [Food choices: College students' food and cooking preferences](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) e avaliará vários algoritmos de classificação para determinar sua eficácia. O objetivo é entender como diferentes métodos de aprendizado de máquina se comportam em relação à acurácia na classificação de dados.\n",
        "\n",
        "O exercício será dividido em várias etapas:\n",
        "\n",
        "1. **Pré-processamento dos dados:**\n",
        "   - Descreva brevemente o conjunto de dados   \n",
        "   - Limpe o conjunto de dados, tratando valores ausentes, removendo duplicatas e realizando transformações necessárias.\n",
        "   - Caso você use os dados pré-processados na lista anterior, faça um breve descritivo dos principais ajustes.\n",
        "   - Codifique variáveis categóricas, se necessário, para que possam ser utilizadas em algoritmos de aprendizado de máquina.\n",
        "   - Cria a coluna `self_perception_overweight` com valor: `True` se a coluna `self_perception_weight` tem valor 4 ou 5; e `False`, caso contrário.\n",
        "   - Remova a coluna `self_perception_weight` do conjunto de dados.\n",
        "2. **Divisão do conjunto de dados:**\n",
        "   - Divida o conjunto de dados em um conjunto de treinamento e um conjunto de teste para avaliar o desempenho dos algoritmos.\n",
        "   - O mesmo conjunto de teste deve ser usado por todos os algoritmos analizados e nenhum dado deste pode ser usado na fase de treinamento.\n",
        "   - O atributo alvo (*rótulo*) da classificação será o campo `self_perception_overweight`.   \n",
        "3. **Seleção de algoritmos de classificação:**\n",
        "   - Selecione uma variedade de algoritmos de aprendizado de máquina para testar na tarefa de classificação.   \n",
        "   - Sua seleção deve conter, no mínimo, os seguintes métodos: Naive Bayes, k-Nearest Neighbors, Support Vector Machine (Linear/RBF), Decision Trees, Random Forest, Multilayer Perceptron.\n",
        "   - Descreva brevemente como funciona cada algoritmo selecionado.\n",
        "4. **Treinamento e avaliação:**\n",
        "   - Treine os algoritmos de classificação usando todo o conjunto de treinamento.\n",
        "   - Avalie o desempenho de cada algoritmo no conjunto de teste usando métricas como acurácia, precisão, recall e F1-score.\n",
        "   - Repita a análise treinando os algoritmos com validação cruzada.\n",
        "   - Repita a análise realizando ajuste de hiperparâmetros.\n",
        "5. **Análise dos resultados:**\n",
        "   - Prepare um texto que descreva os resultados obtidos e faça uma análise crítica destes resultados.\n",
        "   - Compare o desempenho dos diferentes algoritmos e explique por que alguns apresentaram resultados mais adequados que outros.\n",
        "   \n",
        "Documente todas as etapas em um arquivo Jupyter Notebook (`.ipynb`) que inclua as análises, o código e as justificativas. Lembre-se de que é fundamental justificar todas as decisões tomadas ao longo do processo e documentar as análises de forma clara e concisa. Este trabalho tem como objetivo proporcionar uma compreensão prática da seleção e avaliação de algoritmos de classificação em cenários de aprendizado supervisionado.\n",
        "\n",
        "Envie seu Jupyter Notebook até a data de entrega especificada nesta tarefa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2jUsZem07qo"
      },
      "source": [
        "## Solução\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JisjMFpR07qp"
      },
      "source": [
        "### Pré-processamento dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2mx5X9O07qq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZXfAewjI07qr"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/She-Codes-Now/Intro-to-Data-Science-with-R/master/food_coded.csv\")\n",
        "#df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2YXKdKC09nS_"
      },
      "outputs": [],
      "source": [
        "def is_number(x):\n",
        "    try:\n",
        "        float(x)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "#Pega um número de dentro de uma string\n",
        "def extrair_numeros(string):\n",
        "    lista = re.findall(r'\\d+\\.\\d+|\\d+', string)\n",
        "    if len(lista) == 0:\n",
        "        return np.nan\n",
        "    else:\n",
        "        return float(lista[0])\n",
        "    return lista\n",
        "\n",
        "# Função para converter a coluna para valores numéricos\n",
        "def to_numeric(df):\n",
        "    return df.map(lambda x: float(x) if is_number(x) else extrair_numeros(x))\n",
        "\n",
        "def to_lower_case(df):\n",
        "    return df.apply(lambda x: x.str.lower() if x.dtype == 'object' else x)\n",
        "\n",
        "def replace_slash_with_comma(df):\n",
        "    return df.apply(lambda x: x.str.replace('/', ',') if x.dtype == 'object' else x)\n",
        "def replace_r_with_comma(df):\n",
        "    return df.apply(lambda x: x.str.replace('\\r', ',') if x.dtype == 'object' else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_u-fJ7PZ9w7N"
      },
      "outputs": [],
      "source": [
        "gpa = ['GPA']\n",
        "weight = ['weight']\n",
        "\n",
        "\n",
        "# Criando o transformer para a coluna GPA\n",
        "gpa_transformer = Pipeline(steps=[\n",
        "    ('to_numeric', FunctionTransformer(to_numeric)),\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "]).set_output(transform='pandas')\n",
        "\n",
        "\n",
        "weight_transformer = Pipeline(steps=[\n",
        "    ('to_numeric', FunctionTransformer(to_numeric)),\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "],).set_output(transform='pandas')\n",
        "\n",
        "\n",
        "preprocessing = ColumnTransformer(transformers=[\n",
        "    ('GPA', gpa_transformer, ['GPA']),\n",
        "    ('weight', weight_transformer, ['weight']),\n",
        "], remainder='passthrough').set_output(transform='pandas')\n",
        "\n",
        "df = preprocessing.fit_transform(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vuqtb8cO9ttF"
      },
      "outputs": [],
      "source": [
        "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# Identificar as colunas do tipo object (geralmente colunas de texto ou categóricas)\n",
        "object_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "])\n",
        "\n",
        "string_transformer = Pipeline(steps=[\n",
        "    ('to_lower_case', FunctionTransformer(to_lower_case)),\n",
        "    ('replace_slash_with_comma', FunctionTransformer(replace_slash_with_comma)),\n",
        "    ('replace_r_with_comma', FunctionTransformer(replace_r_with_comma)),\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
        "])\n",
        "\n",
        "# Usando ColumnTransformer para aplicar a transformação na coluna GPA\n",
        "preprocessing = ColumnTransformer(transformers=[\n",
        "    ('numeric', numeric_transformer, numeric_columns),  # Aplica a transformação nas colunas numéricas\n",
        "    ('object', string_transformer, object_columns)\n",
        "], remainder='passthrough').set_output(transform='pandas')\n",
        "\n",
        "\n",
        "# Aplicando a transformação no DataFrame\n",
        "df2 = preprocessing.fit_transform(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "R430SkOF-TZR",
        "outputId": "9dd3d61c-bff4-493b-8568-4f28f2874017"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>numeric__GPA__GPA</th>\n",
              "      <th>numeric__weight__weight</th>\n",
              "      <th>numeric__remainder__Gender</th>\n",
              "      <th>numeric__remainder__breakfast</th>\n",
              "      <th>numeric__remainder__calories_chicken</th>\n",
              "      <th>numeric__remainder__calories_day</th>\n",
              "      <th>numeric__remainder__calories_scone</th>\n",
              "      <th>numeric__remainder__coffee</th>\n",
              "      <th>numeric__remainder__comfort_food_reasons_coded</th>\n",
              "      <th>numeric__remainder__cook</th>\n",
              "      <th>...</th>\n",
              "      <th>object__remainder__eating_changes</th>\n",
              "      <th>object__remainder__father_profession</th>\n",
              "      <th>object__remainder__fav_cuisine</th>\n",
              "      <th>object__remainder__food_childhood</th>\n",
              "      <th>object__remainder__healthy_meal</th>\n",
              "      <th>object__remainder__ideal_diet</th>\n",
              "      <th>object__remainder__meals_dinner_friend</th>\n",
              "      <th>object__remainder__mother_profession</th>\n",
              "      <th>object__remainder__type_sports</th>\n",
              "      <th>self_perception_overweight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.111111</td>\n",
              "      <td>187.00000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>eat faster</td>\n",
              "      <td>profesor</td>\n",
              "      <td>arabic cuisine</td>\n",
              "      <td>rice  and chicken</td>\n",
              "      <td>looks not oily</td>\n",
              "      <td>being healthy</td>\n",
              "      <td>rice, chicken,  soup</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>car racing</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.807778</td>\n",
              "      <td>155.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>i eat out more than usual.</td>\n",
              "      <td>self employed</td>\n",
              "      <td>italian</td>\n",
              "      <td>chicken and biscuits, beef soup, baked beans</td>\n",
              "      <td>grains, veggies, (more of grains and veggies),...</td>\n",
              "      <td>try to eat 5-6 small meals a day. while trying...</td>\n",
              "      <td>pasta, steak, chicken</td>\n",
              "      <td>nurse rn</td>\n",
              "      <td>basketball</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.611111</td>\n",
              "      <td>159.04918</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>sometimes choosing to eat fast food instead of...</td>\n",
              "      <td>owns business</td>\n",
              "      <td>italian</td>\n",
              "      <td>mac and cheese, pizza, tacos</td>\n",
              "      <td>usually includes natural ingredients; nonproce...</td>\n",
              "      <td>i would say my ideal diet is my current diet</td>\n",
              "      <td>chicken and rice with veggies, pasta, some kin...</td>\n",
              "      <td>owns business</td>\n",
              "      <td>none</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.555556</td>\n",
              "      <td>240.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>accepting cheap and premade,store bought foods</td>\n",
              "      <td>mechanic</td>\n",
              "      <td>turkish</td>\n",
              "      <td>beef stroganoff, tacos, pizza</td>\n",
              "      <td>fresh fruits&amp; vegetables, organic meats</td>\n",
              "      <td>healthy, fresh veggies,fruits &amp; organic foods</td>\n",
              "      <td>grilled chicken ,stuffed shells,homemade chili</td>\n",
              "      <td>special education teacher</td>\n",
              "      <td>hockey</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.722222</td>\n",
              "      <td>190.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>i have eaten generally the same foods but i do...</td>\n",
              "      <td>it</td>\n",
              "      <td>italian</td>\n",
              "      <td>pasta, chicken tender, pizza</td>\n",
              "      <td>a lean protein such as grilled chicken, green ...</td>\n",
              "      <td>ideally i would like to be able to eat healthi...</td>\n",
              "      <td>chicken parmesan, pulled pork, spaghetti and m...</td>\n",
              "      <td>substance abuse conselor</td>\n",
              "      <td>softball</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0.722222</td>\n",
              "      <td>156.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>610.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>i have noticed there is less time for a prepar...</td>\n",
              "      <td>accountant</td>\n",
              "      <td>italian</td>\n",
              "      <td>stromboli mac and cheese and pizza</td>\n",
              "      <td>mainly protein and vegetables with a complex c...</td>\n",
              "      <td>my ideal diet would consist of a majority of w...</td>\n",
              "      <td>pasta, fish, steak</td>\n",
              "      <td>radiological technician</td>\n",
              "      <td>softball</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>0.444444</td>\n",
              "      <td>180.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>265.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>eating pizza as an excuse when there is nothin...</td>\n",
              "      <td>doctor</td>\n",
              "      <td>mexican food</td>\n",
              "      <td>isombe , plantains and ugali</td>\n",
              "      <td>a healthy meal is a variety of food , organic ...</td>\n",
              "      <td>eating home cooked meals everyday and being ab...</td>\n",
              "      <td>fried rice ,baked potatoes ,curry chicken</td>\n",
              "      <td>public health advisor</td>\n",
              "      <td>basketball</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>0.934444</td>\n",
              "      <td>120.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>less rice</td>\n",
              "      <td>ceo of company</td>\n",
              "      <td>korean</td>\n",
              "      <td>rice and potato</td>\n",
              "      <td>lots of vegetables</td>\n",
              "      <td>lots of veggies</td>\n",
              "      <td>meat, rice, kimchi</td>\n",
              "      <td>real estate manageer</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>0.444444</td>\n",
              "      <td>135.00000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>i don't eat as much on a daily basis since com...</td>\n",
              "      <td>store manager at giant eagle</td>\n",
              "      <td>italian</td>\n",
              "      <td>pizza and spaghetti</td>\n",
              "      <td>a protein, a fruit, a starch, and a salad or s...</td>\n",
              "      <td>my ideal diet is the diet i am currently on.  ...</td>\n",
              "      <td>pizza, spaghetti, baked ziti</td>\n",
              "      <td>receptionist for a medical supply company</td>\n",
              "      <td>hockey</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>0.944444</td>\n",
              "      <td>135.00000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>i have learned to eat more vegetables.</td>\n",
              "      <td>journalist</td>\n",
              "      <td>hispanic cuisine.</td>\n",
              "      <td>rice, beans, and chicken , pizza, tenders</td>\n",
              "      <td>a cup of rice, vegetables, and meat.</td>\n",
              "      <td>being able to balance between sweets, vegetabl...</td>\n",
              "      <td>vegetables, meat, and rice.</td>\n",
              "      <td>house-wife</td>\n",
              "      <td>hockey</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>125 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     numeric__GPA__GPA  numeric__weight__weight  numeric__remainder__Gender  \\\n",
              "0             0.111111                187.00000                         2.0   \n",
              "1             0.807778                155.00000                         1.0   \n",
              "2             0.611111                159.04918                         1.0   \n",
              "3             0.555556                240.00000                         1.0   \n",
              "4             0.722222                190.00000                         1.0   \n",
              "..                 ...                      ...                         ...   \n",
              "120           0.722222                156.00000                         1.0   \n",
              "121           0.444444                180.00000                         1.0   \n",
              "122           0.934444                120.00000                         1.0   \n",
              "123           0.444444                135.00000                         2.0   \n",
              "124           0.944444                135.00000                         1.0   \n",
              "\n",
              "     numeric__remainder__breakfast  numeric__remainder__calories_chicken  \\\n",
              "0                              1.0                                 430.0   \n",
              "1                              1.0                                 610.0   \n",
              "2                              1.0                                 720.0   \n",
              "3                              1.0                                 430.0   \n",
              "4                              1.0                                 720.0   \n",
              "..                             ...                                   ...   \n",
              "120                            1.0                                 610.0   \n",
              "121                            1.0                                 265.0   \n",
              "122                            1.0                                 720.0   \n",
              "123                            1.0                                 720.0   \n",
              "124                            1.0                                 430.0   \n",
              "\n",
              "     numeric__remainder__calories_day  numeric__remainder__calories_scone  \\\n",
              "0                                 3.0                               315.0   \n",
              "1                                 3.0                               420.0   \n",
              "2                                 4.0                               420.0   \n",
              "3                                 3.0                               420.0   \n",
              "4                                 2.0                               420.0   \n",
              "..                                ...                                 ...   \n",
              "120                               4.0                               420.0   \n",
              "121                               2.0                               315.0   \n",
              "122                               3.0                               420.0   \n",
              "123                               4.0                               420.0   \n",
              "124                               3.0                               315.0   \n",
              "\n",
              "     numeric__remainder__coffee  \\\n",
              "0                           1.0   \n",
              "1                           2.0   \n",
              "2                           2.0   \n",
              "3                           2.0   \n",
              "4                           2.0   \n",
              "..                          ...   \n",
              "120                         2.0   \n",
              "121                         2.0   \n",
              "122                         1.0   \n",
              "123                         1.0   \n",
              "124                         2.0   \n",
              "\n",
              "     numeric__remainder__comfort_food_reasons_coded  numeric__remainder__cook  \\\n",
              "0                                               9.0                       2.0   \n",
              "1                                               1.0                       3.0   \n",
              "2                                               1.0                       1.0   \n",
              "3                                               2.0                       2.0   \n",
              "4                                               1.0                       1.0   \n",
              "..                                              ...                       ...   \n",
              "120                                             2.0                       3.0   \n",
              "121                                             2.0                       3.0   \n",
              "122                                             2.0                       3.0   \n",
              "123                                             2.0                       3.0   \n",
              "124                                             2.0                       3.0   \n",
              "\n",
              "     ...                  object__remainder__eating_changes  \\\n",
              "0    ...                                        eat faster    \n",
              "1    ...                        i eat out more than usual.    \n",
              "2    ...  sometimes choosing to eat fast food instead of...   \n",
              "3    ...     accepting cheap and premade,store bought foods   \n",
              "4    ...  i have eaten generally the same foods but i do...   \n",
              "..   ...                                                ...   \n",
              "120  ...  i have noticed there is less time for a prepar...   \n",
              "121  ...  eating pizza as an excuse when there is nothin...   \n",
              "122  ...                                          less rice   \n",
              "123  ...  i don't eat as much on a daily basis since com...   \n",
              "124  ...            i have learned to eat more vegetables.    \n",
              "\n",
              "     object__remainder__father_profession  object__remainder__fav_cuisine  \\\n",
              "0                               profesor                   arabic cuisine   \n",
              "1                          self employed                          italian   \n",
              "2                           owns business                         italian   \n",
              "3                               mechanic                         turkish    \n",
              "4                                      it                        italian    \n",
              "..                                    ...                             ...   \n",
              "120                           accountant                         italian    \n",
              "121                                doctor                    mexican food   \n",
              "122                        ceo of company                          korean   \n",
              "123          store manager at giant eagle                         italian   \n",
              "124                            journalist               hispanic cuisine.   \n",
              "\n",
              "                object__remainder__food_childhood  \\\n",
              "0                              rice  and chicken    \n",
              "1    chicken and biscuits, beef soup, baked beans   \n",
              "2                    mac and cheese, pizza, tacos   \n",
              "3                   beef stroganoff, tacos, pizza   \n",
              "4                   pasta, chicken tender, pizza    \n",
              "..                                            ...   \n",
              "120            stromboli mac and cheese and pizza   \n",
              "121                  isombe , plantains and ugali   \n",
              "122                               rice and potato   \n",
              "123                          pizza and spaghetti    \n",
              "124     rice, beans, and chicken , pizza, tenders   \n",
              "\n",
              "                       object__remainder__healthy_meal  \\\n",
              "0                                      looks not oily    \n",
              "1    grains, veggies, (more of grains and veggies),...   \n",
              "2    usually includes natural ingredients; nonproce...   \n",
              "3             fresh fruits& vegetables, organic meats    \n",
              "4    a lean protein such as grilled chicken, green ...   \n",
              "..                                                 ...   \n",
              "120  mainly protein and vegetables with a complex c...   \n",
              "121  a healthy meal is a variety of food , organic ...   \n",
              "122                                 lots of vegetables   \n",
              "123  a protein, a fruit, a starch, and a salad or s...   \n",
              "124              a cup of rice, vegetables, and meat.    \n",
              "\n",
              "                         object__remainder__ideal_diet  \\\n",
              "0                                       being healthy    \n",
              "1    try to eat 5-6 small meals a day. while trying...   \n",
              "2         i would say my ideal diet is my current diet   \n",
              "3       healthy, fresh veggies,fruits & organic foods    \n",
              "4    ideally i would like to be able to eat healthi...   \n",
              "..                                                 ...   \n",
              "120  my ideal diet would consist of a majority of w...   \n",
              "121  eating home cooked meals everyday and being ab...   \n",
              "122                                    lots of veggies   \n",
              "123  my ideal diet is the diet i am currently on.  ...   \n",
              "124  being able to balance between sweets, vegetabl...   \n",
              "\n",
              "                object__remainder__meals_dinner_friend  \\\n",
              "0                                 rice, chicken,  soup   \n",
              "1                               pasta, steak, chicken    \n",
              "2    chicken and rice with veggies, pasta, some kin...   \n",
              "3       grilled chicken ,stuffed shells,homemade chili   \n",
              "4    chicken parmesan, pulled pork, spaghetti and m...   \n",
              "..                                                 ...   \n",
              "120                                 pasta, fish, steak   \n",
              "121          fried rice ,baked potatoes ,curry chicken   \n",
              "122                                 meat, rice, kimchi   \n",
              "123                       pizza, spaghetti, baked ziti   \n",
              "124                        vegetables, meat, and rice.   \n",
              "\n",
              "          object__remainder__mother_profession  \\\n",
              "0                                   unemployed   \n",
              "1                                    nurse rn    \n",
              "2                                owns business   \n",
              "3                    special education teacher   \n",
              "4                     substance abuse conselor   \n",
              "..                                         ...   \n",
              "120                   radiological technician    \n",
              "121                     public health advisor    \n",
              "122                       real estate manageer   \n",
              "123  receptionist for a medical supply company   \n",
              "124                                 house-wife   \n",
              "\n",
              "     object__remainder__type_sports  self_perception_overweight  \n",
              "0                        car racing                       False  \n",
              "1                       basketball                        False  \n",
              "2                              none                       False  \n",
              "3                            hockey                        True  \n",
              "4                          softball                        True  \n",
              "..                              ...                         ...  \n",
              "120                        softball                        True  \n",
              "121                     basketball                         True  \n",
              "122                            none                        True  \n",
              "123                          hockey                       False  \n",
              "124                          hockey                       False  \n",
              "\n",
              "[125 rows x 61 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#df2['numeric__remainder__self_perception_weight']\n",
        "df2['self_perception_overweight'] = df2['numeric__remainder__self_perception_weight'].apply(lambda x: True if x == 4 or x == 5 else False)\n",
        "# Change the following line to drop the column by name\n",
        "df2 = df2.drop(columns=['numeric__remainder__self_perception_weight'])\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMIPFHZZ07qt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbFuyqL807qt"
      },
      "source": [
        "### Divisão do conjunto de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny3KxNcw07qu"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Modelo de NB tratamento de Colunas não numericas (String)\n",
        "def dropText(df):\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype == 'object':\n",
        "            df.drop(column, axis=1, inplace=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2 = dropText(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_qGRFeuT07qu"
      },
      "outputs": [],
      "source": [
        "X_food = df2.drop(columns=['self_perception_overweight'], axis=1)\n",
        "y_food = df2['self_perception_overweight']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3le03FeoFpX9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_food, y_food, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-ub5m6107qu"
      },
      "source": [
        "### Seleção de algoritmos de classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ## 1° Naive Bayes (NB) \n",
        "O algoritmo de Naïve Bayes no Scikit-learn é um método probabilístico, baseado no Teorema de Bayes, que assume independência entre as variáveis preditoras. Ele é eficiente para classificação de textos, filtragem de spam e outras tarefas. O Scikit-learn implementa variantes como GaussianNB, MultinomialNB e BernoulliNB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ## 2° k-Nearest Neighbors (kNN)\n",
        "O k-Nearest Neighbors (kNN) é um algoritmo de aprendizado supervisionado usado para classificação e regressão. Ele funciona identificando os \"k\" vizinhos mais próximos de um dado ponto com base em uma métrica de distância, como a Euclidiana. A classificação é feita pela maioria dos votos entre os vizinhos, enquanto a regressão usa a média dos valores. Simples e eficiente, o kNN é ideal para problemas pequenos, mas pode ser computacionalmente caro em conjuntos de dados grandes. Ele é sensível à escala dos dados e à escolha do parâmetro \"k\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ## 3° Support Vector Machine (SVM)\n",
        "O Support Vector Machine (SVM) é um algoritmo de aprendizado supervisionado usado para classificação e regressão, que busca encontrar um hiperplano ótimo que separe os dados em diferentes classes. Na versão linear, o SVM utiliza um hiperplano linear para separar os dados. Já com o kernel RBF (Radial Basis Function), ele mapeia os dados para um espaço de maior dimensão, permitindo a separação de padrões complexos de forma não linear. O SVM é eficaz em conjuntos de dados de alta dimensionalidade, mas requer uma boa escolha dos hiperparâmetros para evitar overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ## 4° Decision Trees\n",
        "As Decision Trees são modelos de aprendizado supervisionado usados para tarefas de classificação e regressão. Elas funcionam segmentando iterativamente os dados em subconjuntos baseados em perguntas ou condições sobre os atributos, formando uma estrutura hierárquica em forma de árvore. Cada nó interno representa uma decisão, cada ramo uma possível saída, e as folhas contêm as previsões finais. São intuitivas, fáceis de interpretar e lidam bem com dados mistos (numéricos e categóricos), mas podem sofrer de overfitting, especialmente em árvores muito profundas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ## 5° Random Forest  \n",
        "O Random Forest é um algoritmo de aprendizado supervisionado baseado em conjuntos (ensemble), que combina múltiplas árvores de decisão para melhorar a precisão e reduzir o risco de overfitting. Ele constrói várias árvores independentes usando subconjuntos aleatórios de dados e atributos, e a previsão final é obtida pela média (regressão) ou pelo voto majoritário (classificação) das árvores. É robusto contra outliers e overfitting, além de lidar bem com dados complexos e de alta dimensionalidade. No entanto, pode ser computacionalmente intensivo para grandes conjuntos de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ## 6° Multilayer Perceptron \n",
        "O Multilayer Perceptron (MLP) é um tipo de rede neural artificial usado para aprendizado supervisionado, capaz de realizar tarefas de classificação e regressão. Ele é composto por pelo menos três camadas: entrada, ocultas (uma ou mais) e saída. As camadas ocultas contêm neurônios que usam funções de ativação não lineares, permitindo ao MLP modelar padrões complexos e não lineares nos dados. Treinado com algoritmos como backpropagation, o MLP é versátil, mas pode exigir muitos dados e ajuste fino dos hiperparâmetros para alcançar bom desempenho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HkGsLCt07qv"
      },
      "source": [
        "### Treinamento e avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Zq1ylMcY07qv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia: 0.67\n",
            "Precisão: 0.67\n",
            "Recall: 0.67\n",
            "F1-Score: 0.67\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "#Naive Bayes (NB)\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "nb_model.fit(X_train,y_train)\n",
        "\n",
        "# Avaliação inicial no conjunto de teste\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Calcular as métricas\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')  # Pode ser 'micro', 'macro', 'weighted' dependendo do seu problema\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Acurácia: {accuracy:.2f}\")\n",
        "print(f\"Precisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia: 0.60\n",
            "Precisão: 0.56\n",
            "Recall: 0.60\n",
            "F1-score:0.58\n"
          ]
        }
      ],
      "source": [
        "#K-Nearest Neighbor (kNN)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Acurácia: {accuracy:.2f}\")\n",
        "print(f\"Precisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score:{f1:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia: 0.60\n",
            "Precisão: 0.62\n",
            "Recall: 0.60\n",
            "F1-score:0.61\n"
          ]
        }
      ],
      "source": [
        "#Support Vector Machines (SVM)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = SVC(kernel='linear')\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted') \n",
        "\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Acurácia: {accuracy:.2f}\")\n",
        "print(f\"Precisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score:{f1:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia: 0.74\n",
            "Precisão: 0.73\n",
            "Recall: 0.74\n",
            "F1-score:0.73\n"
          ]
        }
      ],
      "source": [
        "#Decision Trees\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')  \n",
        "\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Acurácia: {accuracy:.2f}\")\n",
        "print(f\"Precisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score:{f1:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia: 0.74\n",
            "Precisão: 0.72\n",
            "Recall: 0.74\n",
            "F1-score:0.68\n"
          ]
        }
      ],
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Acurácia: {accuracy:.2f}\")\n",
        "print(f\"Precisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score:{f1:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia: 0.62\n",
            "Precisão: 0.49\n",
            "Recall: 0.62\n",
            "F1-score:0.55\n"
          ]
        }
      ],
      "source": [
        "#Multilayer Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "model = MLPClassifier(hidden_layer_sizes=(5, 3), activation='relu', max_iter=1000, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Acurácia: {accuracy:.2f}\")\n",
        "print(f\"Precisão: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score:{f1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Avalaicao do desempenho de cada algoritmo no conjunto de teste usando métricas como acurácia, precisão, recall e F1-score.\n",
        "\n",
        "| Algoritmo                             | Acurácia | Precisão | Recall | F1-Score |\n",
        "|---------------------------------------|----------|----------|--------|----------|\n",
        "| Naive Baye                           |    0.67  |    0.67  |  0.67  |    0.67  |\n",
        "| k-Nearest Neighbors                  |    0.60  |    0.56  |  0.60  |    0.58  |\n",
        "| Support Vector Machine (Linear/RBF)  |    0.60  |    0.62  |  0.60  |    0.61  |\n",
        "| Decision Trees                       |    0.74  |    0.73  |  0.74  |    0.73  |\n",
        "| Random Forest                        |    0.74  |    0.72  |  0.74  |    0.68  |\n",
        "| Multilayer Perceptron                |    0.62  |    0.49  |  0.62  |    0.55  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvxeZjkg07qv"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaeXDDPu07qw"
      },
      "source": [
        "### Análise dos resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qGIoeaa07qw"
      },
      "source": [
        "# Treinando os algoritmos com validação cruzada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XCepX8E407qw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo: Naive Bayes\n",
            "Acurácia: 0.73\n",
            "Precisão: 0.68\n",
            "Recall: 0.68\n",
            "F1-score: 0.67\n",
            "--------------------------------------------------\n",
            "Modelo: k-NN\n",
            "Acurácia: 0.58\n",
            "Precisão: 0.43\n",
            "Recall: 0.43\n",
            "F1-score: 0.40\n",
            "--------------------------------------------------\n",
            "Modelo: SVM\n",
            "Acurácia: 0.70\n",
            "Precisão: 0.85\n",
            "Recall: 0.50\n",
            "F1-score: 0.41\n",
            "--------------------------------------------------\n",
            "Modelo: Decision Tree\n",
            "Acurácia: 0.63\n",
            "Precisão: 0.60\n",
            "Recall: 0.58\n",
            "F1-score: 0.59\n",
            "--------------------------------------------------\n",
            "Modelo: Random Forest\n",
            "Acurácia: 0.71\n",
            "Precisão: 0.81\n",
            "Recall: 0.54\n",
            "F1-score: 0.53\n",
            "--------------------------------------------------\n",
            "Modelo: MLP\n",
            "Acurácia: 0.57\n",
            "Precisão: 0.59\n",
            "Recall: 0.51\n",
            "F1-score: 0.46\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
        "\n",
        "models = {\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"k-NN\": KNeighborsClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"MLP\": MLPClassifier(max_iter=2000,learning_rate_init=0.001)\n",
        "}\n",
        "\n",
        "# Funções para calcular as métricas de Precision, Recall e F1-score\n",
        "scoring_metrics = {\n",
        "    \"Acurácia\": \"accuracy\",\n",
        "    \"Precisão\": make_scorer(precision_score, average='macro', zero_division=1),\n",
        "    \"Recall\": make_scorer(recall_score, average='macro', zero_division=1),\n",
        "    \"F1-score\": make_scorer(f1_score, average='macro', zero_division=1)\n",
        "}\n",
        "\n",
        "# Aplicação da validação cruzada\n",
        "for name, model in models.items():\n",
        "    print(f\"Modelo: {name}\")\n",
        "    for metric_name, metric in scoring_metrics.items():\n",
        "        scores = cross_val_score(model, X_food, y_food, cv=10, scoring=metric)\n",
        "        print(f\"{metric_name}: {scores.mean():.2f}\")\n",
        "    print('-' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Algoritmo                             | Acurácia | Precisão | Recall | F1-Score |\n",
        "|---------------------------------------|----------|----------|--------|----------|\n",
        "| Naive Baye                           |    0.73  |    0.68  |  0.68  |    0.67  |\n",
        "| k-Nearest Neighbors                  |    0.58  |    0.43  |  0.43  |    0.40  |\n",
        "| Support Vector Machine (Linear/RBF)  |    0.70  |    0.85  |  0.50  |    0.41  |\n",
        "| Decision Trees                       |    0.67  |    0.59  |  0.58  |    0.55  |\n",
        "| Random Forest                        |    0.73  |    0.85  |  0.58  |    0.48  |\n",
        "| Multilayer Perceptron                |    0.66  |    0.53  |  0.48  |    0.50  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análise realizando ajuste de hiperparâmetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo: Naive Bayes\n",
            "Acurácia: 0.73\n",
            "Precisão: 0.68\n",
            "Recall: 0.68\n",
            "F1-score: 0.67\n",
            "--------------------------------------------------\n",
            "Modelo: k-NN\n",
            "Acurácia: 0.62\n",
            "Precisão: 0.49\n",
            "Recall: 0.44\n",
            "F1-score: 0.38\n",
            "--------------------------------------------------\n",
            "Modelo: SVM\n",
            "Acurácia: 0.70\n",
            "Precisão: 0.85\n",
            "Recall: 0.50\n",
            "F1-score: 0.41\n",
            "--------------------------------------------------\n",
            "Modelo: Decision Tree\n",
            "Acurácia: 0.70\n",
            "Precisão: 0.70\n",
            "Recall: 0.57\n",
            "F1-score: 0.53\n",
            "--------------------------------------------------\n",
            "Modelo: Random Forest\n",
            "Acurácia: 0.74\n",
            "Precisão: 0.71\n",
            "Recall: 0.57\n",
            "F1-score: 0.57\n",
            "--------------------------------------------------\n",
            "Modelo: MLP\n",
            "Acurácia: 0.70\n",
            "Precisão: 0.85\n",
            "Recall: 0.51\n",
            "F1-score: 0.38\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
        "\n",
        "models = {\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"k-NN\": KNeighborsClassifier(algorithm='auto',n_neighbors=9,weights='uniform'),\n",
        "    \"SVM\": SVC(C=0.1, gamma='scale',kernel='rbf'),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(criterion='entropy',max_depth=3,min_samples_leaf=1,min_samples_split=5),\n",
        "    \"Random Forest\": RandomForestClassifier(bootstrap=False,max_depth=10,min_samples_leaf=1,min_samples_split=5,n_estimators=100),\n",
        "    \"MLP\": MLPClassifier(activation='relu',hidden_layer_sizes=(50,),max_iter=2000,learning_rate_init=0.1,solver='adam')\n",
        "}\n",
        "\n",
        "# Funções para calcular as métricas de Precision, Recall e F1-score\n",
        "scoring_metrics = {\n",
        "    \"Acurácia\": \"accuracy\",\n",
        "    \"Precisão\": make_scorer(precision_score, average='macro', zero_division=1),\n",
        "    \"Recall\": make_scorer(recall_score, average='macro', zero_division=1),\n",
        "    \"F1-score\": make_scorer(f1_score, average='macro', zero_division=1)\n",
        "}\n",
        "\n",
        "# Aplicação da validação cruzada\n",
        "for name, model in models.items():\n",
        "    print(f\"Modelo: {name}\")\n",
        "    for metric_name, metric in scoring_metrics.items():\n",
        "        scores = cross_val_score(model, X_food, y_food, cv=10, scoring=metric)\n",
        "        print(f\"{metric_name}: {scores.mean():.2f}\")\n",
        "    print('-' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Algoritmo                             | Acurácia | Precisão | Recall | F1-Score |\n",
        "|---------------------------------------|----------|----------|--------|----------|\n",
        "| Naive Baye                           |    0.73  |    0.68  |  0.68  |    0.67  |\n",
        "| k-Nearest Neighbors                  |    0.62  |    0.49  |  0.44  |    0.38  |\n",
        "| Support Vector Machine (Linear/RBF)  |    0.70  |    0.85  |  0.50  |    0.41  |\n",
        "| Decision Trees                       |    0.70  |    0.71  |  0.57  |    0.55  |\n",
        "| Random Forest                        |    0.75  |    0.75  |  0.60  |    0.59  |\n",
        "| Multilayer Perceptron                |    0.70  |    0.85  |  0.53  |    0.40  |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resultados\n",
        "| Algoritmo                             | Acurácia | Precisão | Recall | F1-Score |\n",
        "|---------------------------------------|----------|----------|--------|----------|\n",
        "| Naive Baye                           |    0.67  |    0.67  |  0.67  |    0.67  |\n",
        "| k-Nearest Neighbors                  |    0.60  |    0.56  |  0.60  |    0.58  |\n",
        "| Support Vector Machine (Linear/RBF)  |    0.60  |    0.62  |  0.60  |    0.61  |\n",
        "| Decision Trees                       |    0.74  |    0.73  |  0.74  |    0.73  |\n",
        "| Random Forest                        |    0.74  |    0.72  |  0.74  |    0.68  |\n",
        "| Multilayer Perceptron                |    0.62  |    0.49  |  0.62  |    0.55  |\n",
        " \n",
        "---\n",
        "\n",
        "| Algoritmo                             | Acurácia | Precisão | Recall | F1-Score |\n",
        "|---------------------------------------|----------|----------|--------|----------|\n",
        "| Naive Baye                           |    0.73  |    0.68  |  0.68  |    0.67  |\n",
        "| k-Nearest Neighbors                  |    0.58  |    0.43  |  0.43  |    0.40  |\n",
        "| Support Vector Machine (Linear/RBF)  |    0.70  |    0.85  |  0.50  |    0.41  |\n",
        "| Decision Trees                       |    0.67  |    0.59  |  0.58  |    0.55  |\n",
        "| Random Forest                        |    0.73  |    0.85  |  0.58  |    0.48  |\n",
        "| Multilayer Perceptron                |    0.66  |    0.53  |  0.48  |    0.50  |\n",
        "\n",
        "---\n",
        "\n",
        "| Algoritmo                             | Acurácia | Precisão | Recall | F1-Score |\n",
        "|---------------------------------------|----------|----------|--------|----------|\n",
        "| Naive Baye                           |    0.73  |    0.68  |  0.68  |    0.67  |\n",
        "| k-Nearest Neighbors                  |    0.62  |    0.49  |  0.44  |    0.38  |\n",
        "| Support Vector Machine (Linear/RBF)  |    0.70  |    0.85  |  0.50  |    0.41  |\n",
        "| Decision Trees                       |    0.70  |    0.71  |  0.57  |    0.55  |\n",
        "| Random Forest                        |    0.75  |    0.75  |  0.60  |    0.59  |\n",
        "| Multilayer Perceptron                |    0.70  |    0.85  |  0.53  |    0.40  |\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sem validacao cruzada\n",
        "O Random Forest e as Decision Trees se destacaram com acurácia de 0.74, mas o Random Forest apresentou uma queda no F1-Score (0.68).\n",
        "O Naive Bayes teve desempenho consistente (0.67 em todas as métricas).\n",
        "SVM, k-NN e MLP apresentaram desempenho inferior, com acurácias abaixo de 0.63."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Com validação cruzada\n",
        "O desempenho geral caiu levemente, refletindo o impacto de uma avaliação mais rigorosa.\n",
        "Random Forest e Naive Bayes ainda lideram em acurácia (0.73), enquanto o k-NN teve o pior desempenho geral, com acurácia de 0.58 e F1-Score de 0.40.\n",
        "A SVM mostrou alta precisão (0.85), mas com baixo recall (0.50), indicando dificuldade em captar todas as classes positivas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Com ajuste de hiperparâmetros\n",
        "Houve melhora geral para a maioria dos modelos, especialmente o Random Forest, que alcançou a melhor acurácia (0.75) e um equilíbrio razoável nas métricas.\n",
        "A SVM manteve alta precisão (0.85), mas o recall permaneceu baixo (0.50), similar ao cenário anterior.\n",
        "Naive Bayes continuou consistente, com resultados semelhantes aos obtidos na validação cruzada.\n",
        "O k-NN mostrou uma pequena melhora em acurácia (0.62), mas ainda foi o algoritmo com desempenho mais fraco em termos gerais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resultado final\n",
        "O Random Forest destacou-se como o melhor modelo geral após o ajuste de hiperparâmetros, equilibrando as métricas. A SVM apresentou alta precisão, mas seu baixo recall pode limitar sua aplicabilidade em problemas sensíveis a falsos negativos. O Naive Bayes mostrou consistência ao longo de todos os cenários, sendo uma opção robusta para dados com características similares."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
